# 선형대수 
> *카이스트 주재걸 교수 <인공지능을 위한 선형대수> 공개강의*    
> *혁펜하임 <보이는 선형대수>*    
> *3Blue1Brown* *"Essence of linear algebra"*


## basics
> [ 01/10 ]     
> dot-product   
> projection     
> vector norm    
> span & column space    
> linearly independent & basis    
> identity / inverse / diagonal / otrhogonal matrix    
> rank    
> null space 

> [ 01/11 ]   
> Gauss-Jordan elimination    
> inverse martix with gauss elimination    
> determinant     
> trace    
> least squares    
> eigen value & eigen vector   
> eigen decomposition    
>     

> [ 01/12 ]     
> linear equation    
> linear system    
> identity matrix & inverse matrix      
> determinant, invertible or not? / rectangular matrix    
> linear combination - vector eqation    
> span   
> vector eqation with span    
> multiplications of matrix as linear combination of vectors   
> matrix multiplications as Row Combinations    
> matrix multiplications as sum of outer-product   
> Linear independence   
> subspace    
> basis of subspace    
> rank of matrix   
> Linear Transformation : matrix as a function     
> matrix of linear transformation   
> linear trans with Neural Network   
> Affine layer in NN   
> Onto and one-to-one   

> [ 01/13 ]  
> onto, one-to-one with fully connected layers   
> Least Square problem   
> vector norm, distance, angle    
> over determined system : which one is a better solution?      
> normal equation  
> derivation of normal equation   
> orthogonal projection    
> orthogonal sets & orthonormal sets   
> neural net as a projection   

> [ 01/15 ]  
> Gram-Schumidt orthogonalization
> QR factorization   
> eigen value & eigen vectors    
> computational advantage of eigen vectors      
> null space and eigen vectors   
> orthogonal complement    
> characteristic equation     
> diagonalization       

> [ 01/17 ]   
> eigen decomposition   
> linear transformation via eigen decomposition   
> change of basis   
> element-wise scaling   
> back to original basis   

[ 01/19 ]   
> singular vector decomposition   
> PCA   
> eigen decomposition in ML   
> feature by data-item & vector similarity   
> diemnsion-reducing transformation   









